{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking whether the following TICs have pre-processed LCs on MAST..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightkurve as lk\n",
    "import astropy.units as u\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for pre-processed lightcurve\n",
    "\n",
    "Target = []\n",
    "data = pd.read_csv(\"hajdu_rrl_binary_TIC_matched.csv\")\n",
    "\n",
    "#Please replace {TIC} with the name of the column containing the source ID.\n",
    "\n",
    "data_array = data[\"TIC\"].to_numpy()\n",
    "#______________________________________________________________________________________\n",
    "for i, TIC in enumerate(data_array):\n",
    "    Target_name = str(TIC)\n",
    "    try:\n",
    "        lk.search_lightcurvefile(Target_name, mission=\"TESS\").download_all().SAP_FLUX\n",
    "        print(\"Available\")\n",
    "    except AttributeError:\n",
    "        print(str(\"TIC\")+str(TIC)+\" processed lightcurve not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for Target Pixel File (TPF)\n",
    "\n",
    "from lightkurve import search_targetpixelfile\n",
    "\n",
    "Target = []\n",
    "data = pd.read_csv(\"hajdu_rrl_binary_TIC_matched.csv\")\n",
    "data_array = data[\"TIC\"].to_numpy()\n",
    "#______________________________________________________________________________________\n",
    "for i, TIC in enumerate(data_array):\n",
    "    Target_name = str(TIC)\n",
    "    try:\n",
    "        tpf = search_targetpixelfile(Target_name)\n",
    "        print(\"Available\")\n",
    "    except AttributeError:\n",
    "        print(str(\"TIC\")+str(TIC)+\" processed lightcurve not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading all the target pixel files. Continue for 'n' tpfs.\n",
    "\n",
    "from lightkurve import search_targetpixelfile\n",
    "\n",
    "tpf1 = search_targetpixelfile(\"TIC 231224520\", campaign=111).download()\n",
    "tpf1\n",
    "tpf2 = search_targetpixelfile(\"TIC 231224520\", campaign=112).download()\n",
    "tpf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean and attach all the normalized lightcurves calculated using the above tpfs. Be very very careful about the normalization.\n",
    "\n",
    "lc1 = tpf1.to_lightcurve(aperture_mask=tpf1.pipeline_mask)\n",
    "lc1.remove_nans()\n",
    "lc1.remove_outliers()\n",
    "lc1_norm = lc1.normalize()\n",
    "lc1.scatter()\n",
    "\n",
    "lc2 = tpf2.to_lightcurve(aperture_mask=tpf2.pipeline_mask)\n",
    "lc2.remove_nans()\n",
    "lc2.remove_outliers()\n",
    "lc2_norm = lc2.normalize()\n",
    "lc2.scatter()\n",
    "\n",
    "lc_all = lk.LightCurve.append(lc1_norm, lc2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "\n",
    "lc_all.scatter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
